{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Informe TP 1 Machine Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para los dos primeros experimentamos decidimos usar el dataset Pima Indians Diabetes Data Set.\n",
      "Este es un dataset de clasificaci\u00f3n num\u00e9rico, con 768 instancias y 8 atributos \n",
      "https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "IDT"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para intentar ver el efecto del overfitting, creamos un Desicion Tree variando la cantidad de nodos m\u00e1ximos a la hora de construir el \u00e1rbol"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_nodes = range(2,150,1)\n",
      "for i in max_nodes:\n",
      "    clf = tree.DecisionTreeClassifier(max_leaf_nodes=i).fit(X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/IDTwithSeed60.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En el gr\u00e1fico se puede ver claramente el efecto de overfitting. El train y test score aumentan hasta alrededor de los 20 nodos m\u00e1ximos, a partir de ah\u00ed  el train score sigue subiendo hasta alcanzar el 100% de aciertos, mientras el test score empieza a caer. \n",
      "\n",
      "Esto sucede ya que el modelo generado al entrenar deja de poder generalizar y se termina transformando casi en un if gigante con todos los casos de train.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A continuaci\u00f3n quisimos ver como afecta a los Decision Tree el agregar ruido a las clases de las mediciones.\n",
      "\n",
      "Para esto cambiamos aleatoriamente un porcentaje de los datos de train a la clase opuesta (nuestro dataset consta de dos clases).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "noise_percentages = [0,0.1,0.2,0.3,0.4,0.5]\n",
      "noise_idx = np.random.random(Y_train.shape)\n",
      "    for noise in noise_percentages:\n",
      "        y_train_with_noise = Y_train.copy()\n",
      "        y_train_with_noise[noise_idx<noise] = np.ones(y_train_with_noise[noise_idx<noise].shape) - y_train_with_noise[noise_idx<noise]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/IDTwithSeed60noise50.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Analizando el gr\u00e1fico anterior, no logramos ver un efecto significativo al agregar ruido a los datos.\n",
      "Por lo que concluimos que los Decision Tree son un clasificador robusto"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "KNN"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A continuaci\u00f3n analizaremos el comportamiento de KNN, para eso prebiamente normalizamos los datos. Esto genera que una variable cuyo rango sea mucho mayor tenga m\u00e1s preponderancia a la hora de clasificar"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y, test_size=0.2 ,random_state=seed)\n",
      "testScores[weights] = []\n",
      "NeighborsCount = range(1,600,20)\n",
      "    for i in NeighborsCount:\n",
      "        clf = KNeighborsClassifier(n_neighbors=i, algorithm='ball_tree',weights='distance').fit(X_train,Y_train)\n",
      "        trainScores[weights].append(clf.score(X_train,Y_train))\n",
      "        testScores[weights].append(clf.score(X_test,Y_test))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/KnnwithSeed0andWeightdistance.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En el gr\u00e1fico podemos ver otra vez el efecto de overfitting en la curva de Test score.\n",
      "\n",
      "La curva de Test converge al porcentaje de la clase mayoritaria. Ya que al tener encuenta a todos los vecinos, el clasificador devuelve siempre la clase mayoritaria.\n",
      "\n",
      "Adem\u00e1s vemos que la curva de Train score es constantemente 1, esto ocurre ya que la funci\u00f3n de peso sobre los vecinos es 1/distancia y como el clasificador ya vio la instancia de train, la distancia a esta es 0 y su peso se vuelve infinito. Por lo que siempre acierta la clase para el conjunto de Train"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/KnnwithSeed20andWeightuniform.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En este gr\u00e1fico vemos el mismo experimento que el anterior pero usando como funci\u00f3n de peso para los vecinos 'uniform'. Que los pesa uniformemente.\n",
      "\n",
      "Otra vez se ve el overfitting, y que al crecer la cantidad de vecinos que se tienen en cuenta, el clasificador converge al porcentaje de la clase mayoritaria.\n",
      "\n",
      "Tanto Test y Train convergen al mismo valor, ya que la muestra esta tomada de la misma distribuci\u00f3n."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/KnnwithSeed0andWeightNoise.png\">"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Naive Bayes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usamos un HashingVector provisto por sklearn para preprocesar el texto de las noticias y sacar las stopwords\n",
      "\n",
      "Tomamos como stop words para el idioma castellano de http://www.ranks.nl/stopwords/spanish"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stop_words = ['un','una','unas','unos','uno','sobre','todo','tambi\u00e9n','tras','otro','alg\u00fan','alguno','alguna','algunos','algunas','ser','es','soy','eres','somos','sois','estoy','esta','estamos','estais','estan','como','en','para','atras','porque','porqu\u00e9','estado','estaba','ante','antes','siendo','ambos','pero','por','poder','puede','puedo','podemos','podeis','pueden','fui','fue','fuimos','fueron','hacer','hago','hace','hacemos','haceis','hacen','cada','fin','incluso','primero','desde','conseguir','consigo','consigue','consigues','conseguimos','consiguen','ir','voy','va','vamos','vais','van','vaya','gueno','ha','tener','tengo','tiene','tenemos','teneis','tienen','el','la','lo','las','los','su','aqui','mio','tuyo','ellos','ellas','nos','nosotros','vosotros','vosotras','si','dentro','solo','solamente','saber','sabes','sabe','sabemos','sabeis','saben','ultimo','largo','bastante','haces','muchos','aquellos','aquellas','sus','entonces','tiempo','verdad','verdadero','verdadera','cierto','ciertos','cierta','ciertas','intentar','intento','intenta','intentas','intentamos','intentais','intentan','dos','bajo','arriba','encima','usar','uso','usas','usa','usamos','usais','usan','emplear','empleo','empleas','emplean','ampleamos','empleais','valor','muy','era','eras','eramos','eran','modo','bien','cual','cuando','donde','mientras','quien','con','entre','sin','trabajo','trabajar','trabajas','trabaja','trabajamos','trabajais','trabajan','podria','podrias','podriamos','podrian','podriais','yo','aquel']\n",
      "\n",
      "vectorizer = HashingVectorizer(decode_error='ignore', n_features=2 ** 18,\n",
      "                               non_negative=True,stop_words=stop_words)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Luego dividimos en un conjunto de train y otro de test, creamos el clasificador, lo entrenemos, testeamos y conseguimos la matriz de confusi\u00f3n "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
      "clf = MultinomialNB(alpha=0.01)\n",
      "clf.fit(X_train,Y_train)\n",
      "conf_matrix = metrics.confusion_matrix(Y_test,clf.predict(X_test)) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}