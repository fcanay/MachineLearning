{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico N2 Aprendizaje Automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrantes\n",
    "#### Federico Canay\n",
    "#### Diego Raffo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este trabajo planteamos como objetivo poder discriminar imágenes y categorizarlas como perro o gato, si es que en ellas aparecía un perro o un gato respectivamente. Para esto se contó con un dataset de prueba de 25.000 imágenes.\n",
    "Para esto se desarrolló una herramienta que a partir de una muestra de imágenes ya categorizadas, intenta discriminar nuevas imágenes no categorizadas,  asignándolas al grupo de perros o de gatos. \n",
    "\n",
    "El desarrollo se hizo en python, usando bibliotecas numéricas como numpy y scipy y bibliotecas de aprendizaje automático como sklearn, openCV y mahotas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesión 1: Extracción de Atributos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al trabajar con un problema de imágenes se agrega un paso extra y de suma importancia para generar un clasificador, la extracción de atributos.\n",
    "\n",
    "No se puede ingresar como input de un algoritmo de ML una imagen (la representación matricial de sus pixeles en escala de grises o RGB), ya que imágenes de diferentes resoluciones, tendrían diferentes cantidad de atributos generando que solo pueda clasificar imagenes de cierta resolución (además de necesitar suficientes imágenes de esa resolución para poder entrenarlo). A esto se le suma que las imágenes tienen una semántica espacial, al representar la imagen como un vector de pixeles, estamos perdiendo información. Ya que un pixel no solo depende de el pixel a su derecha e izquierda sino también de los de su alrededor.\n",
    "    \n",
    "Por esta extraemos atributos de una imagen y este será el input de nuestros algoritmos.\n",
    "\n",
    "Es importante recalcar que la cantidad de atributos tiene que ser independiente de la imagen (o sea, a toda imagen se le debe asignar la misma cantidad de atributos).\n",
    "\n",
    "Para trabajar las imágenes usamos opencv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos una imagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3e5637e9c4b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(imageFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y cuando generamos atributos sobre imágenes blanco y negro, transformamos la imagen a blanco y negro de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primera aproximación decidimos generar un histograma de la distribución de grises y de colores en la imagen.\n",
    "En el caso de escala de grises se genera un vector de 256 componentes, cada uno corresponde a la cantidad de pixeles de ese valor de la escala de grises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generación de histograma blanco y negro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "hist,bins = np.histogram(image.flatten(),256,[0,256])\n",
    "return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El caso de color es muy parecido solo que generamos un histograma para cada color de la descomposición RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(image)\n",
    "b_hist,bins = np.histogram(b.flatten(),256,[0,256])\n",
    "g_hist,bins = np.histogram(g.flatten(),256,[0,256])\n",
    "r_hist,bins = np.histogram(r.flatten(),256,[0,256])\n",
    "return np.concatenate((b_hist,g_hist,r_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Aunque es una primera es una primera aproximación, nuestra hipótesis es que no tenga un gran desempeño ya que tanto perros y gatos suelen tener colores similares y suponemos que entonces la distribución de los mismas no servirá para distinguirlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patrones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentamos buscar patrones de texturas dentro de cada imagenes, desde algunos simples y generales a otros un poco más específicos. Todos estos patrones se hicieron en blanco y negro, ya que el número de posibles patrones crece exponencialmente y se vuelve inmanejable al considerar más de 2 estados para cada color (claro y oscuro). Al armar los patrones definimos como un pixel claro (0) a los pixels cuya escala de grises sea inferior a 128, y oscuros (1) al resto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oscuro(gris):\n",
    "    if gris > 127:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra idea es que estos patrones logren identificar las texturas características de tanto perros como gatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### ’2x2’ y ‘3x3’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los patrones de 2 x 2 son patrones en grupos cuadrados de 4 pixeles donde se buscan todas las combinaciones posibles de pixeles claros y oscuros, como los acabamos de definir. El diccionario de patrones se arma de la siguiente manera. Hay 16 posibles patrones (ya que cada pixel tiene dos opciones), así tendremos 16 atributos, que representará la cantidad de veces que encontramos ese patrón en la imagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "greyImage = cv2.cvtColor(greyImage, cv2.COLOR_BGR2GRAY)\n",
    "patterns_dict = {'0000':0,'0001':0,'0010':0,'0100':0,'1000':0,'0011':0,'0101':0,'0110':0,'0111':0,'1001':0,'1010':0,'1011':0,'1100':0,'1101':0,'1110':0,'1111':0}\n",
    "for i in xrange(greyImage.shape[0]-1):\n",
    "    for j in xrange(greyImage.shape[1]-1):\n",
    "        pattern = str(oscuro(greyImage[i,j])) + str(oscuro(greyImage[i+1,j]))+ str(oscuro(greyImage[i,j+1]))+ str(oscuro(greyImage[i+1,j+1]))\n",
    "        if pattern in patterns_dict:\n",
    "            patterns_dict[pattern] += 1\n",
    "        else:\n",
    "            patterns_dict[pattern] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de el diccionario creado se pueden obtener la cantidad de apariciones de cada patrón en la imagen analizada.\n",
    "\n",
    "El caso de los patrones de 3x3 es bastante similar, solo que los grupos de pixeles cuadrados es de 9 pixeles y no de 4. Esto genera 512 patrones posibles, y como en el caso anterior 512 atributos, donde cada atributo representa la cantidad de veces que se encontró ese patrón en la imagen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "greyImage = cv2.cvtColor(greyImage, cv2.COLOR_BGR2GRAY)\n",
    "patterns_dict = [0] * 512\n",
    "for i in xrange(greyImage.shape[0]-2):\n",
    "    for j in xrange(greyImage.shape[1]-2):\n",
    "        pattern = 0\n",
    "        for x in xrange(0,3):\n",
    "            for y in xrange(0,3):\n",
    "                pattern += oscuro(greyImage[i+x,j+y]) * (2**(y+(3*x)))\n",
    "                patterns_dict[pattern] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar patrones más grandes nos da un poco más de especificidad, y de noción de textura, que podría resultar mejor para poder distinguir perros de gatos.\n",
    "\n",
    "Usar este tipo de patrones todavía más grande se vuelve impracticable, ya que si tomamos cuadrados de 5x5, tendrán 25 pixeles generando 2^25 posibles patrones aprox 35 millones. lo que generaría 35 millones de atributos, algo completamente inmanejable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Patrones circulares (también conocidos como Local Binary Patterns )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta búsqueda de patrones, se intenta ahondar un poco más en esta idea de buscar texturas.  La idea general es que para un pixel dado (en color rojo) setear una distancia y una cantidad de puntos (en color verde) a los cuales comparar con el pixel central, en cuanto a si son mas claros o mas oscuros. De esta forma se formamos patrones más grande pero sin aumentar la cantidad de posibles patrones, ya que no se tienen en cuenta todos los puntos del cuadrado y además se unen patrones simétricos (todos los semicírculos serán considerados el mismo patrón sin importar hacia qué lado apunten)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./imagenes/local_binary_pattern.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lograr esto usamos la librería mahotas que implementa este patrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "return mahotas.features.lbp(image, radius, points, ignore_zeros=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La combinación inicial de radio y cantidad de puntos que se utilizaron originalmente para las pruebas fueron respectivamente: (2,5), (2,9), (3,5), (3,9),(5,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de generar múltiples conjuntos de atributos es hora de analizarlos.\n",
    "Para esto experimentamos, usando diferentes formas de medir cuán 'buenos' son los atributos\n",
    "\n",
    "Para las comparaciones que usan un clasificador genérico usamos nuestro primer clasificador que (como explicaremos en la sección correspondiente), está formado por un voter entre un RandomForest, un Adaboost, GradientBoost y un SVM cada uno con los mejores parámetros encontrados en el GridSearch\n",
    "\n",
    "Es importante tener en cuenta que no todos los conjuntos de atributos tienen la misma cantidad de atributos, como muestra el siguiente gráfico.\n",
    "\n",
    "![title](./imagenes/cant_atributos_x_batch.png)\n",
    "\n",
    "En el mismo se ve el crecimiento exponencial del que hablamos de los patrones NxN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score de los atributos de a uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primera medida se entrenó la herramienta de selección de imágenes utilizando cada atributo por separado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./imagenes/comparacion_atributos_de_a_uno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se observa en el gráfico, es el score de cada atributo individualmente es muy similar, desprendiéndose ligeramente el patrón circular con 9 puntos, en un radio de 5 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score de los atributos sacando de  a uno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro posible análisis que se hizo es el de entrenar la herramienta con todos los atributos a excepción de uno y ver como cambia el score de la herramienta.\n",
    "\n",
    "Hay que tener en cuenta que a mayor score, peor es el conjunto de atributos (ya que si se consigue buen score sin él, significa que no estaría aportando mucha información)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./imagenes/comparacion_atributos_sacando_uno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que al igual que en el primer gráfico, hay una diferencia muy poco marcada entre todos los subconjuntos de atributos que se probaron, con una diferencia de aproximadamente 5% entre la mejor performance (habiendo sacado el histograma en blanco y negro) y la peor performance (habiendo sacado el patrón circular de 5 puntos con radio de 2 pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis univariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis univariado consiste en comparar cada atributo por separado.\n",
    "\n",
    "Las dos formas usuales de encontrar su importancia es ver cuál es su varianza (un atributo constante no aporta ninguna información), o hacer un test de chi2 entre el atributo y la clase para evaluar la dependencia entre ambas (si el atributo es independiente o se cree independiente de la clase, no me sirve para inferir la misma).\n",
    "\n",
    "En nuestro caso usaremos el chi2 ya que provee más información que la varianza.\n",
    "\n",
    "Para este análisis se utilizó la PercentilSelecion de la biblioteca Sklean.feature_selection\n",
    "Este método selecciona el k-percentil de variables más dependientes a la clase según el test chi2. En nuestro caso nos quedaremos con el 20-percentil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchs = ['histogramaByN','histogramaColor','patrones2x2ByN','patrones3x3ByN','patronesCirculaesByN_2_5','patronesCirculaesByN_2_9','patronesCirculaesByN_3_9','patronesCirculaesByN_5_9','patronesCirculaesByN_3_5']\n",
    "X = []\n",
    "y = []\n",
    "load_batch(y,path,'clases',filename) \n",
    "y = [j for i in y for j in i]\n",
    "for batch in batchs:\n",
    "    load_batch(X,path,batch,filename)\n",
    "        \n",
    "sp = SelectPercentile(chi2,20)\n",
    "X_new = sp.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La contrapartida de este método es que se analiza comparando un atributo con la clase, perdiendo así la relación de conjunto de los atributos. Por ejemplo se puede llegar a la conclusión de que cada color por separado no aporta mucha información, pero tal vez al tener los tres colores juntos brinda muchísima información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./imagenes/univar_cant_var.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./imagenes/univar_porcentaj_var.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los gráficos anteriores podemos ver la cantidad de variables que se toman de cada extracción de atributos, que porcentaje de cada selección de atributos se utilizó.\n",
    "Es importante no olvidar que cada conjunto tiene diferente cantidad de variables.\n",
    "Por ejemplo en el primer gráfico parece que el patrón 2x2 o el Circular 2 5 tienen poca importancia, pero es lo opuesto, se seleccionaron todas sus atributos. \n",
    "\n",
    "Podemos ver por ejemplo, como el histograma de color aporta significativamente más variables que el resto de los atributos, pero si lo medimos en porcentaje solo un casi 20% de sus variables son relevantes. Además de los patrones de 2 x 2 y los patrones circulares de 5 puntos con radio de 2 pixeles, el patrón Circular 3 5 también aporta un gran porcentaje de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis multivariado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis multivariado, en contraposición al análisis univariado. Evalúa a todos los atributos en conjunto, pudiendo detectar la relación entre los atributos que comentamos anteriormente.\n",
    "\n",
    "Aprovechamos los árboles de decisión que internamente hacen este proceso al decidir por qué atributo branchear, usando entre otras opciones es minimizar la entropía o usar Gain Ratio.\n",
    "\n",
    "En este análisis se usó el ExtraTreesClassifier de la biblioteca sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "fi = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./imagenes/multivar_porcentaj_acum.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./imagenes/multivar_porcentaj_prom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso nos volvemos a encontrar con el tema de los conjuntos de atributos con diferentes cardinalidades. Si tenemos en cuenta la importancia de los conjuntos como un todo, el histograma color y el patrón 3x3 son los más importantes. Pero esto sucede ya que ambos son los que tienen mayor cantidad de atributos.\n",
    "\n",
    "En cambio si vemos la importancia relativa de cada atributo, lo de los patrones 2x2 son los más importantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo realizado los análisis anteriores, podemos sacar algunas conclusiones.\n",
    "\n",
    "Consideramos que el conjunto de atributos más importante es el de patrones 2x2, ya que como se vio tanto en el análisis univariado como multivariado, es quien tiene mayor importancia relativa. O sea sus pocos atributos concentran muchas información.\n",
    "\n",
    "\n",
    "En un inicio de la experimentación pensamos que iba a ser necesario no tener en cuenta todos los conjuntos de atributos por un tema de tiempo de entrenamiento. Además se puede generar una caída de la performance debido al problema conocido y tratado en el trabajo anterior de la curse of dimensionality.\n",
    "\n",
    "Para nuestra sorpresa nos encontramos con que no sólo no perjudica el score usar todos los atributos, sino que tampoco conlleva una diferencia de tiempo sustancial(la gran diferencia la encontramos en la cantidad de imágenes utilizadas al entrenar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sesión 2:Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En un primer momento pensamos un esquema donde se unían a través de un voter, una instancia de 4 algoritmos vistos (RandomForest,AdaBoosting,SVM y GradientBoosting) y cada una de estas instancias se optimizaba a sus mejores parámetros usando GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est = [RandomForest(),Boosting(),SVM(),Gradient()]\n",
    "clf = VotingClassifier(estimators=est)\n",
    "\n",
    "def Boosting():\n",
    "    tuned_parameters = [{'n_estimators':[30,50,75],'learning_rate':[0.25,0.5,0.75,1]}]\n",
    "    return ('Boosting',GridSearchCV(AdaBoostClassifier(), tuned_parameters,v=5,n_jobs=-1))\n",
    "\n",
    "def RandomForest():\n",
    "    tuned_parameters = {'n_estimators':[5,10,15],'max_features':['sqrt','log2',None],'bootstrap':[True,False]}]\n",
    "    return ('RandomForest',GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=5,n_jobs=-1))\n",
    "\n",
    "def Gradient():\n",
    "    tuned_parameters = [{'loss': ['deviance', 'exponential'],'n_estimators':[75,100,150] ,'learning_rate':[0.05,0.1,0.2]}]\n",
    "    return ('Gradient',GridSearchCV(GradientBoostingClassifier(), tuned_parameters, cv=5,n_jobs=-1))\n",
    "\n",
    "def SVM():\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]},{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "    return ('SVM',GridSearchCV(SVC(), tuned_parameters, cv=5,n_jobs=-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al experimentar, encontramos que este esquema tardaba mucho en entrenarse y que no conseguía una muy buena performance (58%).\n",
    "\n",
    "Encontramos que el cuello de botella del entrenamiento era el GridSearch ya que al hacer una búsqueda exhaustiva en el espacio de parámetros seleccionado tiene que entrenar muchísimas veces cada clasificador (Por ejemplo en el caso de Gradient entrenaba 18 veces).\n",
    "\n",
    "Además nuestra hipótesis de por qué no tiene una muy buena performance, es que la selección de parámetros en el GridSearch optimiza cada clasificador por separado sin tener en cuenta el voter como un todo. No solo pudiendo generar overfitting a los datos de entrenamiento, sino que todos los clasificadores se especialicen en la detección del mismo subset de datos y que todos dejen de lado otro subset.\n",
    "\n",
    "Por esto pasamos a un esquema donde seguimos teniendo un voter para unir los múltiples clasificadores, pero en este caso usamos múltiples instancias de los clasificadores que mejor desempeño tuvieron individualmente (GradientBoosting y SVM como comentaremos en sus respectivas secciones), pero cada instancia tiene sus parámetros fijos de antemano.\n",
    "\n",
    "Así conseguimos un esquema que no solo se entrena más rápido que el anterior ya que cada clasificador se entrena una sola vez, sino que al aumentar la cantidad de clasificadores y la variabilidad de los mismos con los diferentes parámetros, conseguimos una mayor performance (72%). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est = [RandomForest(),Boosting()]\n",
    "for i in xrange(0,10):\n",
    "    est.append(Gradient(i))\n",
    "for i in xrange(0,10):\n",
    "    est.append(SVM(i))\n",
    "\n",
    "clf = VotingClassifier(estimators=est)\n",
    "\n",
    "\n",
    "def Boosting():\n",
    "    return ('Boosting',AdaBoostClassifier())\n",
    "\n",
    "def RandomForest():\n",
    "    return ('RandomForest',RandomForestClassifier()) \n",
    "\n",
    "def Gradient(i=0):\n",
    "    if i==0:\n",
    "        return ('Gradient'+str(i),GradientBoostingClassifier(random_state=i))\n",
    "    elif i==1:\n",
    "        return ('Gradient'+str(i),GradientBoostingClassifier(loss='exponential',random_state=i))\n",
    "    elif i==2:\n",
    "        return ('Gradient'+str(i),GradientBoostingClassifier(loss='exponential',learning_rate=0.2,random_state=i))\n",
    "    elif i==3:\n",
    "        return ('Gradient'+str(i),GradientBoostingClassifier(learning_rate=0.2,random_state=i))\n",
    "    else:\n",
    "        return ('Gradient'+str(i),GradientBoostingClassifier(random_state=i))\n",
    "\n",
    "def SVM(i=0):\n",
    "    if i==0:\n",
    "        return ('SVM'+str(i),SVC(random_state=i))\n",
    "    elif i==1:\n",
    "        return ('SVM'+str(i),SVC(kernel='linear',random_state=i))\n",
    "    elif i==2:\n",
    "        return ('SVM'+str(i),SVC(kernel='linear',C=100,random_state=i))\n",
    "    elif i==3:\n",
    "        return ('SVM'+str(i),SVC(C=100,random_state=i))\n",
    "    elif i==4:\n",
    "        return ('SVM'+str(i),SVC(gamma=1e-3,random_state=i))\n",
    "    elif i==5:\n",
    "        return ('SVM'+str(i),SVC(gamma=1e-4,random_state=i))\n",
    "    else:\n",
    "        return ('SVM'+str(i),SVC(random_state=i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez finalizada la etapa de extracción de atributos cabe preguntarse cómo analizar estos atributos para poder tomar una decisión sobre si la imagen pertenece al grupo de los perros o al grupo de los gatos. \n",
    "\n",
    "Para esto implementaron varios modelos de aprendizaje supervisados independientes, y un sistema de votación donde la catalogación de una imagen será el resultado mayoritario de la catalogación de cada modelo independiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos a experimentar con SVM.\n",
    "\n",
    "En nuestra primera experimentación observamos que las svm con kernel lineal tenían un mucho mejor desempeño que las con kernel rbf (62% vs 48%), yendo en contra de nuestra hipótesis inicial, ya que no creemos que haya una relación lineal entre los atributos seleccionados y la clase.\n",
    "\n",
    "Después de indagar sobre las causas, nos dimos cuenta que en nuestros primeros experimentos la cantidad de imágenes que usábamos era muy pequeña (500 imágenes), en particular menor que  la cantidad de atributos que extrajimos.\n",
    "Esto fue lo que generó el comportamiento que antes describimos, ya que el kernel lineal se comporta bien en estos escenario (muchos atributos en relación a la cantidad de instancias) y el rbf mal.\n",
    "\n",
    "Cuando aumentamos la cantidad de imagenes vimos que como predijimos el desempeño se invertía, cayendo el score del kernel lineal a 52% y aumentando el de rbf a 67%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM(i=0):\n",
    "    if i==0:\n",
    "        return ('SVM'+str(i),SVC(random_state=i))\n",
    "    elif i==1:\n",
    "        return ('SVM'+str(i),SVC(kernel='linear',random_state=i))\n",
    "    elif i==2:\n",
    "        return ('SVM'+str(i),SVC(kernel='linear',C=100,random_state=i))\n",
    "    elif i==3:\n",
    "        return ('SVM'+str(i),SVC(C=100,random_state=i))\n",
    "    elif i==4:\n",
    "        return ('SVM'+str(i),SVC(gamma=1e-3,random_state=i))\n",
    "    elif i==5:\n",
    "        return ('SVM'+str(i),SVC(gamma=1e-4,random_state=i))\n",
    "    else:\n",
    "        return ('SVM'+str(i),SVC(random_state=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnicas de Ensamble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de probar con las SVM, decidimos probar el desempeño de diferentes técnicas de ensamble. Ya que la combinación de múltiples clasificadores más simples ayudan a mejorar la performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos probando con random forest, ya que es muy sencillo y rápido de entrenar. Pero no logramos grandes avances ni siquiera sobre la performance de las svm (tener en cuenta que hablamos de una svm vs un ensamble de árboles de decisión). Conseguimos scores de entre 60% y 62%.\n",
    "\n",
    "En nuestro esquema final mantuvimos un RandomForest como vara de comparación para los demás algoritmos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RandomForest():\n",
    "    return ('RandomForest',RandomForestClassifier()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diferencia del RandomForest en los algoritmos de Boosting, los clasificadores dentro del ensamble no son independientes entre sí (esto es una de las principales razones de que sea necesario más tiempo para su entrenamiento ya que no se puede paralelizar). Los clasificadores se van entrenando en secuencia y cada nuevo clasificador es entrenado teniendo en cuenta lo ya aprendido por el acumulado.\n",
    "\n",
    "Dentro de esta clase de algoritmos probamos dos:\n",
    "\n",
    "-Adaboost:\n",
    "\n",
    "Consiste en una secuencia de weak learners (clasificadores apenas mejores que la elección random) que se entrenan uno tras otro en versiones modificadas de los datos de entrenamiento. Cada nuevo clasificador se entrena sobre el set de entrenamiento pero dándole mayor peso a las instancias que no fueron correctamente clasificadas todavía.\n",
    "    \n",
    "Finalmente todos estos clasificadores se unen en un voter pero asignándole un peso a cada clasificador \n",
    "Usando el este algoritmo conseguimos un score de 67%, mejorando significativamente lo conseguido con RandomFores\n",
    "\n",
    "-GradientBoost: \n",
    "\n",
    "GradientBoost es una generalización del método de Boosting con mayor potencia que el AdaBoost.\n",
    "    \n",
    "Usando este método conseguimos un score del 70%\n",
    "    \n",
    "Al momento de generar el ensamble de clasificadores optamos por tener muchas instancias de GradientBoost sobre AdaBoost, no solo porque tiene una mejor performance, sino porque tiene una mayor variabilidad (variando por ejemplo la loss function). Lo que ayuda a compensar los bias de los clasificadores y conseguir una mejor performance en el voter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último armamos un voter uniendo una instancia de RandomForest y AdaBoost con 10 instancias de GradientBoost y 10 de SVM variando los parámetros de las mismas (ya que tener repetido un mismo clasificador exactamente igual no aporta a la reducción de bias, sino que solo le da más peso a la elección de ese clasificador). \n",
    "\n",
    "El voter consiguió una performance de 72%, aunque nuestra expectativa era que mejore aún más la performance.\n",
    "\n",
    "Además de analizar el porcentaje de aciertos en general, podemos analizar el porcentaje de acierto y falla por clase:\n",
    "\n",
    " <table>\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>Gato</td>\n",
    "    <td>Perro</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Gato</td>\n",
    "    <td>37,0%</td>\n",
    "    <td>11,0%</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Perro</td>\n",
    "    <td>16,4%</td>\n",
    "    <td>35,6%</td>\n",
    "  </tr>\n",
    "</table> \n",
    "\n",
    "Como vemos el porcentaje de aciertos de ambas clases son muy parecidos, pero si dicienten en el porcentaje de fallos.\n",
    "Es un 50% más probable equivocarse al clasificar un perro que un gato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por un lado vimos que a nuestro clasificador le es más dificil clasificar a un perro que a un gato.\n",
    "\n",
    "En segundo lugar, consideramos que una buena selección de atributos es uno de los pasos más importantes en los trabajos de reconocimiento de imágenes. Ya que como vimos ciertos atributos aportan información fundamental para conseguir una buena performance.\n",
    "\n",
    "Por otro lado, creemos que el ensamble generado internamente en el GradientBoost ya es bastante potente por lo que al volver a hacer un ensamble de estos clasificadores con otros (SVM,AdaBoost), el aumento de performance es muy bajo. \n",
    "\n",
    "Además el voter entrena cada modelo independientemente, en cambio el GradientBoost entrena cada modelo sobre 'lo que le falta aprender'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futuros trabajos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Usar el algoritmo surf para generar atributos de los pixels más significativos de la imagen. Hay que tener en cuenta que no se puede usar directamente los piceles destacados por el algoritmo, ya que no habría la misma cantidad para todas las imágenes. Esto se puede resolver por ejemplo teniendo en cuenta el patrón de las vecindad de los puntos destacados y generando un histograma de patrones de 2x2 o 3x3.\n",
    "\n",
    "2.Transformar la imagen previamente, por ejemplo,ecualizándola o usando técnicas de reducción de ruido.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
