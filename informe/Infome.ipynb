{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Informe TP 1 Machine Learning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para los dos primeros experimentamos decidimos usar el dataset Pima Indians Diabetes Data Set.\n",
      "Este es un dataset de clasificaci\u00f3n num\u00e9rico, con 768 instancias y 8 atributos \n",
      "https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "IDT"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para intentar ver el efecto del overfitting, creamos un Desicion Tree variando la cantidad de nodos m\u00e1ximos a la hora de construir el \u00e1rbol"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max_nodes = range(2,150,1)\n",
      "for i in max_nodes:\n",
      "    clf = tree.DecisionTreeClassifier(max_leaf_nodes=i).fit(X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/IDTwithSeed60.png\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En el gr\u00e1fico se puede ver claramente el efecto de overfitting. El train y test score aumentan hasta alrededor de los 20 nodos m\u00e1ximos, a partir de ah\u00ed  el train score sigue subiendo hasta alcanzar el 100% de aciertos, mientras el test score empieza a caer. \n",
      "\n",
      "Esto sucede ya que el modelo generado al entrenar deja de poder generalizar y se termina transformando casi en un if gigante con todos los casos de train.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A continuaci\u00f3n quisimos ver como afecta a los Decision Tree el agregar ruido a las clases de las mediciones.\n",
      "\n",
      "Para esto cambiamos aleatoriamente un porcentaje de los datos de train a la clase opuesta (nuestro dataset consta de dos clases).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "noise_percentages = [0,0.1,0.2,0.3,0.4,0.5]\n",
      "noise_idx = np.random.random(Y_train.shape)\n",
      "    for noise in noise_percentages:\n",
      "        y_train_with_noise = Y_train.copy()\n",
      "        y_train_with_noise[noise_idx<noise] = np.ones(y_train_with_noise[noise_idx<noise].shape) - y_train_with_noise[noise_idx<noise]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "KNN"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Naive Bayes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Usamos un HashingVector provisto por sklearn para preprocesar el texto de las noticias y sacar las stopwords\n",
      "\n",
      "Tomamos como stop words para el idioma castellano de http://www.ranks.nl/stopwords/spanish"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stop_words = ['un','una','unas','unos','uno','sobre','todo','tambi\u00e9n','tras','otro','alg\u00fan','alguno','alguna','algunos','algunas','ser','es','soy','eres','somos','sois','estoy','esta','estamos','estais','estan','como','en','para','atras','porque','porqu\u00e9','estado','estaba','ante','antes','siendo','ambos','pero','por','poder','puede','puedo','podemos','podeis','pueden','fui','fue','fuimos','fueron','hacer','hago','hace','hacemos','haceis','hacen','cada','fin','incluso','primero','desde','conseguir','consigo','consigue','consigues','conseguimos','consiguen','ir','voy','va','vamos','vais','van','vaya','gueno','ha','tener','tengo','tiene','tenemos','teneis','tienen','el','la','lo','las','los','su','aqui','mio','tuyo','ellos','ellas','nos','nosotros','vosotros','vosotras','si','dentro','solo','solamente','saber','sabes','sabe','sabemos','sabeis','saben','ultimo','largo','bastante','haces','muchos','aquellos','aquellas','sus','entonces','tiempo','verdad','verdadero','verdadera','cierto','ciertos','cierta','ciertas','intentar','intento','intenta','intentas','intentamos','intentais','intentan','dos','bajo','arriba','encima','usar','uso','usas','usa','usamos','usais','usan','emplear','empleo','empleas','emplean','ampleamos','empleais','valor','muy','era','eras','eramos','eran','modo','bien','cual','cuando','donde','mientras','quien','con','entre','sin','trabajo','trabajar','trabajas','trabaja','trabajamos','trabajais','trabajan','podria','podrias','podriamos','podrian','podriais','yo','aquel']\n",
      "\n",
      "vectorizer = HashingVectorizer(decode_error='ignore', n_features=2 ** 18,\n",
      "                               non_negative=True,stop_words=stop_words)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Luego dividimos en un conjunto de train y otro de test, creamos el clasificador, lo entrenemos, testeamos y conseguimos la matriz de confusi\u00f3n "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, y, test_size=0.2)\n",
      "clf = MultinomialNB(alpha=0.01)\n",
      "clf.fit(X_train,Y_train)\n",
      "conf_matrix = metrics.confusion_matrix(Y_test,clf.predict(X_test)) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}